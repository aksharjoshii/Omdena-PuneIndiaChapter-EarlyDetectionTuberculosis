{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshar/miniconda3/envs/omdena_agri/lib/python3.11/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.16 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import logging\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from skimage import morphology\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models.segmentation as models\n",
    "from typing import Dict, List\n",
    "import torch.multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/akshar/Omdena/TB Detection/github/Omdena-PuneIndiaChapter-EarlyDetectionTuberculosis'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import CLF_DATA_DIR, PROC_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segmented_lung_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/akshar/Omdena/TB Detection/github/Omdena...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/akshar/Omdena/TB Detection/github/Omdena...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/akshar/Omdena/TB Detection/github/Omdena...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/akshar/Omdena/TB Detection/github/Omdena...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/akshar/Omdena/TB Detection/github/Omdena...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 segmented_lung_path        label\n",
       "0  /home/akshar/Omdena/TB Detection/github/Omdena...  tb_positive\n",
       "1  /home/akshar/Omdena/TB Detection/github/Omdena...  tb_positive\n",
       "2  /home/akshar/Omdena/TB Detection/github/Omdena...  tb_positive\n",
       "3  /home/akshar/Omdena/TB Detection/github/Omdena...  tb_positive\n",
       "4  /home/akshar/Omdena/TB Detection/github/Omdena...  tb_positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/processed/processed_dataset.csv')[['segmented_lung_path', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segmented_lung_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>segmented_lung/tb_positive/a0e8ff5bff05d0c5644...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>segmented_lung/tb_positive/90a02093a5d50b28fb1...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>segmented_lung/tb_positive/83cf58db5b1ef9d68f0...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>segmented_lung/tb_positive/9d2cd99f0580bfc04d5...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>segmented_lung/tb_positive/71f64b8dbec4588b953...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 segmented_lung_path        label\n",
       "0  segmented_lung/tb_positive/a0e8ff5bff05d0c5644...  tb_positive\n",
       "1  segmented_lung/tb_positive/90a02093a5d50b28fb1...  tb_positive\n",
       "2  segmented_lung/tb_positive/83cf58db5b1ef9d68f0...  tb_positive\n",
       "3  segmented_lung/tb_positive/9d2cd99f0580bfc04d5...  tb_positive\n",
       "4  segmented_lung/tb_positive/71f64b8dbec4588b953...  tb_positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['segmented_lung_path'] = df['segmented_lung_path'].str.replace('/home/akshar/Omdena/TB Detection/github/Omdena-PuneIndiaChapter-EarlyDetectionTuberculosis/data/processed/', '', regex=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segmented_lung_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tb_positive/a0e8ff5bff05d0c564450e92346d3fc9_A...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tb_positive/90a02093a5d50b28fb1f21fa371c849f_A...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tb_positive/83cf58db5b1ef9d68f0b7dd8db4c624f_A...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tb_positive/9d2cd99f0580bfc04d57998257a141e4_A...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tb_positive/71f64b8dbec4588b9533ed0c02f1f2d8_A...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 segmented_lung_path        label\n",
       "0  tb_positive/a0e8ff5bff05d0c564450e92346d3fc9_A...  tb_positive\n",
       "1  tb_positive/90a02093a5d50b28fb1f21fa371c849f_A...  tb_positive\n",
       "2  tb_positive/83cf58db5b1ef9d68f0b7dd8db4c624f_A...  tb_positive\n",
       "3  tb_positive/9d2cd99f0580bfc04d57998257a141e4_A...  tb_positive\n",
       "4  tb_positive/71f64b8dbec4588b9533ed0c02f1f2d8_A...  tb_positive"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['segmented_lung_path'] = df['segmented_lung_path'].str.replace(\"segmented_lung/\",\"\", regex=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/akshar/Omdena/TB Detection/github/Omdena-PuneIndiaChapter-EarlyDetectionTuberculosis/data/processed/segmented_lung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segmented_lung_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/akshar/Omdena/TB Detection/github/Omdena...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/akshar/Omdena/TB Detection/github/Omdena...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/akshar/Omdena/TB Detection/github/Omdena...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/akshar/Omdena/TB Detection/github/Omdena...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/akshar/Omdena/TB Detection/github/Omdena...</td>\n",
       "      <td>tb_positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 segmented_lung_path        label\n",
       "0  /home/akshar/Omdena/TB Detection/github/Omdena...  tb_positive\n",
       "1  /home/akshar/Omdena/TB Detection/github/Omdena...  tb_positive\n",
       "2  /home/akshar/Omdena/TB Detection/github/Omdena...  tb_positive\n",
       "3  /home/akshar/Omdena/TB Detection/github/Omdena...  tb_positive\n",
       "4  /home/akshar/Omdena/TB Detection/github/Omdena...  tb_positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# setting up device \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale_truncation(image, **kwargs):\n",
    "    \"\"\"\n",
    "    This function truncates a grayscale image by calculating the minimum and maximum values \n",
    "    from the central region of the image and then applying these values to clip the entire image.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): A 2D numpy array representing the grayscale image. The shape of the array is (height, width).\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: A 2D numpy array representing the truncated grayscale image. The shape of the array is the same as the input image.\n",
    "    \"\"\"\n",
    "    height, width = image.shape \n",
    "    \n",
    "    # Define central region \n",
    "    central_region = image[height//4:3*height//4, width//4:3*width//4]\n",
    "\n",
    "    # Calculate min and max of central region \n",
    "    min_val, max_val = np.min(central_region) , np.max(central_region)\n",
    "\n",
    "    # Truncate the image  \n",
    "    truncated_image = np.clip(image, min_val, max_val)\n",
    "\n",
    "    return truncated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_rgb(image, **kwargs):\n",
    "    \"\"\"\n",
    "    Converts a grayscale image to RGB format.\n",
    "    \"\"\"\n",
    "    return np.stack([image] * 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale_inversion(image, **kwargs):\n",
    "    \"\"\"\n",
    "    Inverts a grayscale image by flipping pixel intensities.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Input grayscale image as a 2D numpy array (shape: HxW) \n",
    "                               or a 3-channel grayscale image (shape: HxW or HxWx1).\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Inverted grayscale image.\n",
    "    \"\"\"\n",
    "    # Ensure the image is single-channel grayscale (2D array)\n",
    "    if len(image.shape) == 3 and image.shape[2] == 1:\n",
    "        image = image.squeeze(-1)\n",
    "    \n",
    "    # Invert pixel intensities: black (0) becomes white (255), white becomes black\n",
    "    inverted_image = 255 - image\n",
    "    \n",
    "    return inverted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(state_dict_path : Path,\n",
    "               device : torch.device):\n",
    "    \"\"\"\n",
    "    Prepare the DeepLabV3_MobileNetV3_Large model for lung segmentation.\n",
    "    \n",
    "    Args:\n",
    "        state_dict_path (Path): The path to the state dictionary file.\n",
    "        device (torch.device): The device to move the model to (e.g., 'cuda' or 'cpu').\n",
    "        \n",
    "    Returns:\n",
    "        torch.nn.Module: The prepared model.\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the state dictionary file does not exist.\n",
    "        RuntimeError: If there is an issue loading the state dictionary.\n",
    "    \"\"\"\n",
    "    # Check if the state dictionary path exists\n",
    "    if not state_dict_path.is_file():\n",
    "        raise FileNotFoundError(f\"State dictionary file not found: {state_dict_path}\")\n",
    "    # initialize the model withoutt pre-trained weights\n",
    "    model = models.deeplabv3_mobilenet_v3_large(weights=None)\n",
    "    # Freeze all layers in the backbone\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Fine-tune the segmentation layer\n",
    "    model.classifier[4] = nn.Conv2d(\n",
    "        in_channels=256,\n",
    "        out_channels=2,  # Adjust based on segmentation task\n",
    "        kernel_size=(1, 1)\n",
    "    )\n",
    "    try:\n",
    "        state_dict = torch.load(state_dict_path, map_location=device)\n",
    "        # Remove the '_orig_mod.' prefix from the keys in the state_dict\n",
    "        state_dict = {k.replace('_orig_mod.', ''): v for k, v in state_dict.items()}\n",
    "        state_dict = {k:v for k, v in state_dict.items() if not k.startswith(\"aux_classifier.\")}\n",
    "        model.load_state_dict(state_dict)\n",
    "    except RuntimeError as e:\n",
    "        raise RuntimeError(f\"Error loading state dictionary: {e}\")   \n",
    "    # Move the model to the specified device\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    # Compile the model \n",
    "    # model = torch.compile(model)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segmented_lung(image, mask):\n",
    "    \"\"\"Creates a segmented lung image with black background.\"\"\"\n",
    "    segmented = image.copy()\n",
    "    segmented[mask == 0] = 0\n",
    "    return segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(SEG_MODEL_PATH,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pre-Processing for Segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image= cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "    image_resized = cv2.resize(image,(520, 520),interpolation=cv2.INTER_LINEAR)\n",
    "    transform = A.Compose([\n",
    "        A.Lambda(image=grayscale_truncation, p=1.0),\n",
    "        A.Lambda(image=grayscale_inversion, p=1.0),\n",
    "        A.Lambda(image=convert_to_rgb, p=1.0),\n",
    "        A.CLAHE(clip_limit=5, tile_grid_size=(8, 8), p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    transformed = transform(image=image_resized)   \n",
    "    return transformed['image'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Post-Processing for Segmented Masks** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian_blur(mask: np.ndarray, kernel_size: tuple) -> np.ndarray:\n",
    "    \"\"\"Apply Gaussian blur to the mask.\"\"\"\n",
    "    return cv2.GaussianBlur(mask, kernel_size, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(mask: np.ndarray, threshold_value: float) -> np.ndarray:\n",
    "    \"\"\"Convert the mask to a binary mask using a threshold.\"\"\"\n",
    "    max_val = np.max(mask)\n",
    "    _, binary_mask = cv2.threshold(mask, threshold_value * max_val, max_val, cv2.THRESH_BINARY)\n",
    "    return binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def post_process_mask(predicted_mask:np.ndarray,\n",
    "                     config : Dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Post-process the predicted lung mask to enhance quality, incorporating erosion and dilation.\n",
    "\n",
    "    Parameters:\n",
    "    - predicted_mask: numpy array, the predicted lung mask output from the model.\n",
    "    - min_object_size: int, the minimum size of objects to keep in the mask (default is 1000).\n",
    "    - opening_size: int, the size of the structuring element used for morphological opening (default is 5).\n",
    "    - erosion_size: int, the size of the structuring element used for erosion (default is 3).\n",
    "    - dilation_size: int, the size of the structuring element used for dilation (default is 3).\n",
    "\n",
    "    Returns:\n",
    "    - processed_mask: numpy array, the post-processed lung mask.\n",
    "    \"\"\"\n",
    "    gaussian_kernel = config.get('gaussian_kernel', (5,5))\n",
    "    threshold_value = config.get('threshold_value', 0.5)\n",
    "    min_object_size = config.get('min_object_size', 1000)\n",
    "    opening_size = config.get('opening_size', 5)\n",
    "    erosion_size = config.get('erosion_size', 3)\n",
    "    dilation_size = config.get('dilation_size', 3)\n",
    "    # Check if the predicted mask is empty\n",
    "    if predicted_mask.size == 0:\n",
    "        logging.warning(\"Predicted mask is empty, returning a zero mask.\")\n",
    "        return np.zeros_like(predicted_mask)\n",
    "    # Step 1: Apply Gaussian Blur\n",
    "    blurred_mask = apply_gaussian_blur(predicted_mask, gaussian_kernel)\n",
    "\n",
    "   # Step 2: Apply Thresholding\n",
    "    binary_mask = apply_threshold(blurred_mask, threshold_value)\n",
    "\n",
    "    # Step 3: Fill holes in the binary mask\n",
    "    filled_mask = binary_fill_holes(binary_mask).astype(np.uint8)\n",
    "\n",
    "    # Step 4: Remove small background objects\n",
    "    cleaned_mask = remove_small_objects(filled_mask.astype(bool), min_size=min_object_size)\n",
    "\n",
    "    # Step 5: Apply morphological opening to remove small objects and smooth boundaries\n",
    "    opening_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (opening_size, opening_size))\n",
    "    opened_mask = cv2.morphologyEx(cleaned_mask.astype(np.uint8), cv2.MORPH_OPEN, opening_kernel)\n",
    "\n",
    "    # Step 6: Apply erosion to shrink the mask and potentially separate connected regions\n",
    "    erosion_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (erosion_size, erosion_size))\n",
    "    eroded_mask = cv2.erode(opened_mask, erosion_kernel, iterations=1)\n",
    "\n",
    "    eroded_mask = (eroded_mask > 0).astype(np.uint8)  #  UPDATES Convert to binary (0 and 1)\n",
    "    # Check if eroded mask is empty before proceeding\n",
    "    if np.sum(eroded_mask) == 0:                                           # DEBUG\n",
    "        print(\"Eroded mask is empty; skipping this mask.\")\n",
    "        return None\n",
    "    \n",
    "    # Step 7: Disconnect spuriously connected regions\n",
    "    num_labels, labels = cv2.connectedComponents(eroded_mask)\n",
    "    largest_components_mask = np.zeros_like(eroded_mask)\n",
    "    for i in range(1, num_labels):  # Skip the background component\n",
    "        component_mask = (labels == i).astype(np.uint8)\n",
    "        if np.sum(component_mask) >= min_object_size:\n",
    "            largest_components_mask += component_mask\n",
    "\n",
    "    # Step 8: Apply dilation to expand the mask and recover lost lung area\n",
    "    dilation_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilation_size, dilation_size))\n",
    "    dilated_mask = cv2.dilate(largest_components_mask.astype(np.uint8), dilation_kernel, iterations=1)\n",
    "\n",
    "    # Step 9: Final cleaning - remove small objects once more\n",
    "    final_mask = remove_small_objects(dilated_mask.astype(bool), min_size=min_object_size)\n",
    "    \n",
    "    # Step 10: Apply Grayscale Truncation\n",
    "    truncated_final_mask = grayscale_truncation(final_mask.astype(np.float32))\n",
    "    \n",
    "    return truncated_final_mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualize Sample results**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def display_random_predictions(model:nn.Module, \n",
    "                               config_dict:Dict, \n",
    "                               image_dir: str, \n",
    "                               device: torch.device, \n",
    "                               num_samples: int =5):\n",
    "    \"\"\"\n",
    "    Displays the original image, predicted mask, processed predicted mask, and segmented lung for random images from the directory.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained segmentation model.\n",
    "        image_dir (str): The directory path containing the images.\n",
    "        device (torch.device): The device to use for inference.\n",
    "        num_samples (int): The number of random samples to display (default is 5).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        # Get list of image files\n",
    "         # Use glob to efficiently find all image files with the desired extensions\n",
    "        image_files = glob(os.path.join(image_dir, '*'))  # This matches .png, .jpg, and .jpeg files\n",
    "        \n",
    "        # Randomly select n images without loading all files into memory at once\n",
    "        random_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "\n",
    "        original_images = []\n",
    "        processed_images = []\n",
    "\n",
    "        # Load and preprocess images\n",
    "        for img_path in random_images:\n",
    "            \n",
    "            # Store original image for display\n",
    "            original_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            original_images.append(original_img)\n",
    "\n",
    "            # Preprocess image for prediction\n",
    "            preprocessed_img = preprocess_image(original_img)  # Use file path for preprocessing\n",
    "            processed_images.append(preprocessed_img)\n",
    "\n",
    "        images = torch.cat(processed_images).to(device)\n",
    "\n",
    "        # Make predictions\n",
    "        outputs = model(images)['out']\n",
    "        \n",
    "        if outputs.shape[1] == 2:\n",
    "            preds = torch.sigmoid(outputs[:, 1, :, :])\n",
    "        else:\n",
    "            preds = torch.sigmoid(outputs.squeeze(1))\n",
    "\n",
    "        # Convert predictions to numpy array for processing and display\n",
    "        predicted_masks = preds.cpu().numpy()\n",
    "\n",
    "        # Apply post-processing to each predicted mask\n",
    "        processed_masks = []\n",
    "        for pred in predicted_masks:\n",
    "            processed_mask = post_process_mask(pred,config_dict)\n",
    "            processed_masks.append(processed_mask)\n",
    "\n",
    "        # Display the results\n",
    "        fig, axes = plt.subplots(num_samples, 4, figsize=(20, 5 * num_samples))  # Adjusted for 4 columns\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # Display original image\n",
    "            axes[i, 0].imshow(original_images[i], cmap='gray')\n",
    "            axes[i, 0].set_title(\"Original Image\")\n",
    "            axes[i, 0].axis('off')\n",
    "\n",
    "            # Display predicted mask before post-processing\n",
    "            pred_resized_before = cv2.resize(predicted_masks[i],\n",
    "                                              (original_images[i].shape[1], original_images[i].shape[0]),\n",
    "                                              interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            axes[i, 1].imshow(pred_resized_before, cmap='gray')\n",
    "            axes[i, 1].set_title(\"Predicted Mask Before Post-Processing\")\n",
    "            axes[i, 1].axis('off')\n",
    "\n",
    "            # Display processed predicted mask after post-processing\n",
    "            pred_resized_after = cv2.resize(processed_masks[i],\n",
    "                                             (original_images[i].shape[1], original_images[i].shape[0]),\n",
    "                                             interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            axes[i, 2].imshow(pred_resized_after, cmap='gray')\n",
    "            axes[i, 2].set_title(\"Processed Predicted Mask\")\n",
    "            axes[i, 2].axis('off')\n",
    "\n",
    "            # Threshold the processed mask to create a binary mask\n",
    "            thresholded_mask = (pred_resized_after > 0.5).astype(np.float32)\n",
    "\n",
    "            # Display segmented lung\n",
    "            segmented_lung = create_segmented_lung(original_images[i], thresholded_mask)\n",
    "            axes[i, 3].imshow(segmented_lung, cmap='gray')\n",
    "            axes[i, 3].set_title(\"Segmented Lung\")\n",
    "            axes[i, 3].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_config = dict(\n",
    "    gaussian_kernel = (5,5),\n",
    "    threshold_value = 0.5,\n",
    "    min_object_size = 1500,\n",
    "    opening_size = 5,\n",
    "    erosion_size = 3,\n",
    "    dilation_size = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "display_random_predictions(model, p_config, \n",
    "                           input_dir,\n",
    "                           device=device, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Processed Image dataset creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(\n",
    "    model: torch.nn.Module,\n",
    "    input_dir: Path,\n",
    "    output_dir: Path,\n",
    "    device: torch.device,\n",
    "    config: dict = None\n",
    "):\n",
    "    \"\"\"Process all images in the specified directory sequentially and save the results.\"\"\"\n",
    "\n",
    "    # Ensure input and output directories exist\n",
    "    if not input_dir.exists():\n",
    "        print(f\"Input directory {input_dir} does not exist.\")\n",
    "        return\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create subdirectories for segmented lungs, predicted masks, and post-processed masks\n",
    "    for class_name in ['tb_positive', 'tb_negative']:\n",
    "        for img_type in ['segmented_lung', 'predicted_mask', 'post_processed_mask']:\n",
    "            (output_dir / img_type / class_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Iterate over both classes 'tb_positive' and 'tb_negative'\n",
    "    for class_name in ['tb_positive', 'tb_negative']:\n",
    "        class_dir = input_dir / class_name\n",
    "\n",
    "        # Get all image filenames\n",
    "        image_filenames = [f for ext in ('*.jpg', '*.png', '*.jpeg') for f in class_dir.glob(ext)]\n",
    "\n",
    "        # Process each image sequentially\n",
    "        for filename in tqdm(image_filenames, desc=f'Processing {class_name} images'):\n",
    "            image_path = class_dir / filename\n",
    "            \n",
    "            # Read original image from input directory\n",
    "            original_image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "            if original_image is None:\n",
    "                print(f\"Failed to read image {image_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Preprocess, predict mask, post-process, and create isolated lung dataset\n",
    "            input_tensor = preprocess_image(str(image_path)).to(device)\n",
    "\n",
    "            # Predict mask for the image\n",
    "            with torch.inference_mode():\n",
    "                output = model(input_tensor)['out']\n",
    "                pred = torch.sigmoid(output[:, 1, :, :]) if output.shape[1] == 2 else torch.sigmoid(output.squeeze(1))\n",
    "\n",
    "            mask = pred.cpu().numpy()\n",
    "            mask = np.squeeze(mask)\n",
    "\n",
    "            # Ensure valid mask shape\n",
    "            if mask.ndim != 2 or mask.size == 0:\n",
    "                print(f\"Invalid mask shape at {image_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Post-process the mask\n",
    "            processed_mask = post_process_mask(mask, config=config)\n",
    "            if processed_mask is None or processed_mask.size == 0:\n",
    "                print(f\"Processed mask is invalid for {image_path}. Skipping.\")\n",
    "                continue \n",
    "\n",
    "            # Resize mask to match original image size\n",
    "            processed_mask_resized = cv2.resize(\n",
    "                processed_mask,\n",
    "                (original_image.shape[1], original_image.shape[0]),\n",
    "                interpolation=cv2.INTER_NEAREST\n",
    "            )\n",
    "\n",
    "            thresholded_mask = (processed_mask_resized > 0.5).astype(np.float32)\n",
    "            isolated_lungs = create_segmented_lung(original_image, thresholded_mask)\n",
    "\n",
    "            # Construct base filename with class name\n",
    "            base_filename = f\"{filename.stem}_{class_name}{filename.suffix}\"\n",
    "\n",
    "            # Save predicted mask\n",
    "            predicted_mask_path = output_dir / 'predicted_mask' / class_name / base_filename\n",
    "            cv2.imwrite(str(predicted_mask_path), (mask * 255).astype(np.uint8))\n",
    "\n",
    "            # Save post-processed mask\n",
    "            post_processed_mask_path = output_dir / 'post_processed_mask' / class_name / base_filename\n",
    "            cv2.imwrite(str(post_processed_mask_path), (processed_mask_resized * 255).astype(np.uint8))\n",
    "\n",
    "            # Save segmented lung\n",
    "            segmented_lung_path = output_dir / 'segmented_lung' / class_name / base_filename\n",
    "            cv2.imwrite(str(segmented_lung_path), isolated_lungs)\n",
    "\n",
    "            results.append({\n",
    "                'input_image_path': str(image_path),\n",
    "                'predicted_mask_path': str(predicted_mask_path),\n",
    "                'post_processed_mask_path': str(post_processed_mask_path),\n",
    "                'segmented_lung_path': str(segmented_lung_path),\n",
    "                'label': class_name\n",
    "            })\n",
    "\n",
    "    # Save results to CSV file\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_dir / 'processed_dataset.csv', index=False)\n",
    "\n",
    "    print(f\"Processed {len(results)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tb_positive images:   0%|          | 0/6222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tb_positive images: 100%|██████████| 6222/6222 [09:26<00:00, 10.99it/s]\n",
      "Processing tb_negative images: 100%|██████████| 6881/6881 [10:32<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 13103 images.\n"
     ]
    }
   ],
   "source": [
    "process_directory(model, \n",
    "                  input_dir=CLF_DATA_DIR, \n",
    "                  output_dir=PROC_DATA_DIR,\n",
    "                  config=p_config,\n",
    "                  device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omdena_agri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
